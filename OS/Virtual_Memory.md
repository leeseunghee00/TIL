## 10.1 배경

**⚠️ 지금까지의 접근 방식은 프로세스 전체가 실행되기 전에 올라와야 한다는 것을 전제로 했다.**

- 실제 프로그램들을 살펴보면 프로그램 전체가 한꺼번에 메모리에 항상 올라와 있어야 하는 것은 아니라는 사실을 쉽게 발견할 수 있다.
    - 예를 들면,
    - 프로그램에는 잘 발생하지 않는 오류 상황을 처리하는 코드가 종종 존재한다.
    - 배열, 리스트, 테이블 등은 필요 이상으로 많은 공간을 점유할 수 있다.
    - 프로그램 내의 어떤 옵션이나 기능들은 거의 사용되지 않는다.

- 만약 프로그램을 일부분만 메모리에 올려놓고 실행할 수 있다면 다음과 같은 이점이 있다.
    - 프로그램은 **물리 메모리 크기에 제약을 받지 않는다.**
        - 사용자들은 매우 큰 가상 주소 공간을 가정하고 프로그램을 만들 수 있어 프로그래밍 작업이 간단해진다.
    - 각 프로그램은 작은 메모리를 차지하므로 **더 많은 프로그램을 동시에 수행**할 수 있게 된다.
        - 응답 시간은 늘어나지 않으면서도 CPU 이용률과 처리율은 높아진다.
    - 프로그램을 메모리에 올리고 스왑하는 데 필요한 I/O 회수가 줄어들기 때문에 프로그램들이 보다 빨리 실행된다.

⇒ ***따라서 가상 메모리를 사용하여 프로세스 전체가 올라오지 않더라도 실행이 가능하도록 한다.***

- **가상 메모리**는 실제  물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것이다.
    - 장점은 작은 메모리를 가지고도 큰 가상 주소 공간을 프로그래머에게 제공할 수 있다.
    - 프로그래머는 메모리 크기에 관련한 문제를 염려할 필요 없이 프로그램을 작성할 수 있다.
        
        ![image](https://user-images.githubusercontent.com/87460638/236807124-50f4768a-398f-4fe5-a3c6-f50560ab32fb.png)
        

- 한 프로세스의 **가상 주소 공간**은 그 프로세스가 메모리에 저장되는 논리적인 모습(view)을 말한다.
    - 일반적으로 특정 논리 주소에서 시작하여 연속적인 공간을 차지한다.
    
- 힙(heap)은 동적 할당 메모리를 사용함에 따라 주소 공간상에서 위쪽으로 확장되고, 스택(stack)은 함수 호출을 거듭함에 따라 주소 공간상에서 아래쪽으로 확장된다.
    - 이때 힙과 스택 사이의 있는 공백을 포함한 가상 주소 공간을 **성긴(sparse) 주소 공간**이라고 한다.
    - 성긴 주소 공간의 공백은 스택이나 힙 세그먼트가 확장될 때 사용되거나 프로그램 실행 중 동적으로 라이브러리를 링크할 필요가 있을 때 사용된다.
    
    ![image](https://user-images.githubusercontent.com/87460638/236807199-67e3547a-62e2-481d-a191-d1e772e38600.png)
    

- 가상 메모리는 페이지 공유를 통해 파일이나 메모리가 둘 또는 그 이상의 프로세스들에 의해 공유되는 것을 가능하게 한다.
    - 장점 중 하나는 표준 C 라이브러리와 같은 시스템 라이브러리가 여러 프로세스들에 공유될 수 있다.
        
        … 각 프로세스는 라이브러리가 자신의 가상 주소 공간 일부라고 생각하지만, 실제로는 라이브러리가 존재하는 물리 메모리 페이지들은 모든 프로세스에 공유되고 있다. 
        
    
    ![image](https://user-images.githubusercontent.com/87460638/236807251-114fe403-bfee-4156-9379-b48acda87238.png)
    

## 10.2 요구 페이징

> **⚠️ 어떻게 실행 프로그램을 보조저장장치에서 메모리로 적재할 수 있을지 생각해 보자.**
> 
1. 프로그램 실행 시작 시 프로그램의 전부를 물리 메모리에 적재 ?
    
    ⇒ 초기에 프로그램의 전체가 메모리에 있을 필요는 없을 수 있다는 문제가 있다 !
    
2. 필요한 페이지만 적재 ?
⇒ 이 기법을 **요구 페이징** 이라고 한다.
⇒ 필요한 프로그램의 일부만 적재하여 메모리를 더 효율적으로 사용될 수 있다 !

### 10.2.1 기본 개념

- 요구 페이징의 기본 개념은 **필요할 때만 페이지를 메모리에 적재하는 것**이다.
    - 결과적으로 프로세스가 실행되는 동안 일부 페이지는 메모리에 있고 일부는 보조저장장치에 있을 수 있다.
    - 따라서 이 둘을 구별하기 위해 하드웨어 지원이 필요하다.

- **유효·무효 비트 기법을 여기에 사용할 수 있다.**
    - 여기서 **유효**는 해당 페이지가 메모리에 있다, **무효**는 해당 페이지가 유효하지 않거나(가상 주소 공간 상에 정의되지 않았거나) 유효하지만 보조저장장치에 존재한다는 의미이다.
- 메모리에 올라오는 페이지에 대해서는 유효로 설정하며, 현재 메모리에 올라와 있지 않은 페이지의 페이지 테이블 항목은 무효로 설정한다.

![image](https://user-images.githubusercontent.com/87460638/236807289-5a77d3ae-f580-4af8-9c95-d3112d48661d.png)

- 프로세스가 메모리에 올라와 있지 않은 페이지에 접근하려고 하면 **페이지 폴트 트랩(page-fault trap)**을 발생시킨다.
    - 페이지 폴트를 처리하는 과정은 다음과 같다.
    
    ![image](https://user-images.githubusercontent.com/87460638/236807334-178b78d6-eb85-49e9-b371-e39ef4d959e4.png)
    
    1. 프로세스에 대한 내부 테이블을 검사해서 그 **메모리 참조가 유효한지 무효한지**를 알아낸다.
    2. 유효하면 그 프로세스는 **중단**되고, 만약 유효한 참조인데 페이지가 아직 메모리에 올라오지 않았다면, 그것을 보조저장장치에 가져와야 한다.
    3. 빈 공간, 즉 **가용 프레임**을 찾는다.
    4. 보조저장장치에 새로 할당된 프레임으로 **해당 페이지를 읽어 들이도록 요청**한다.
    5. 읽기를 마치면 페이지는 메모리에 있다는 것을 알리기 위해 **페이지 테이블을 갱신**하고, 프로세스가 유지하고 있는 **내부 테이블을 수정**한다.
    6. 트랩에 의해 중단되었던 명령어를 **다시 시작**한다.
    
    ⇒ ***이로써 프로세스는 마치 그 페이지가 항상 메모리에 있었던 것처럼 해당 페이지에 접근할 수 있다.***
    
- 극단적인 경우에는 메모리에 **페이지가 하나도 안 올라와 있는 상태**에서도 프로세스를 실행시킬 수 있다.
    - 이는 **순수 요구 페이징(pure demand paging)** 을 사용한 것을 말한다.
    - 어떤 페이지가 필요하기 전에는 결코 그 페이지를 메모리로 적재하지 않는 방법이다.

- 프로그램들은 한 명령어에서도 여러 개의 페이지 폴트를 일으킬 수 있다.
    - 이렇게 되면 시스템 성능의 저하를 초래할 수 있다.
    - 하지만 다행히 모든 프로그램은 **참조의 지역성**의 성질이 있어서 프로그램의 어느 한 특정 작은 부분만 한동안 집중적으로 참조하는데, 이러한 성질 때문에 요구 페이징은 만족할 만한 성능을 보인다.

- 요구 페이징을 지원하기 위해 필요한 하드웨어는 페이징과 스와핑을 위한 하드웨어와 동일하다.
    - **페이지 테이블** : 보호 비트들 특별한 값 or 유효/무효 비트를 통해 특정 항목을 무효로 설정할 수 있어야 한다.
    - **보조저장장치** : 메인 메모리에 없는 모든 페이지를 가지고 있다. 보통 고성능의 디스크 또는 NVM 장치를 스왑 장치라고 하며, 이 목적을 위해 사용하는 저장장치 영역을 **스왑공간**이라고 한다. … ~~이에 관해서는 11장에 논의한다.~~

- 한 명령어가 많은 기억 장소를 변경하는 것일 때 상당히 어려운 문제가 발생한다.
    - 이러한 문제는 두 가지 방법으로 해결할 수 있다.
    1. 마이크로코드로 양 블록의 두 끝을 계산하여 겹치지 않는 것을 확인한 후에 접근을 시도하는 것이다.
        1. 만약 페이지 폴트 가능성이 있다면, 수정하기 전 단계에서 페이지 폴트를 발생시킨다.
        2. 그런 다음에 이동을 시작하면 어떤 페이지 폴트도 일어날 수 없다.
    2. 이동에 의해서 이전의 내용이 지워질 기억 장소들의 값을 보존하기 위해 임시 레지스터들을 사용하는 것이다.
        1. 이러한 작업은 그 명령어가 실행되기 바로 전의 상태를 기억 공간에 다시 복구하며, 명령어가 다시 수행될 수 있다.

### 10.2.2 가용 프레임 리스트

- 페이지 폴트가 발생하면 운영체제는 요청된 페이지를 보조저장장치에서 메인 메모리로 가져와야 한다.
    - 페이지 폴트를 해결하기 위해 대부분의 운영체제는 가용 프레임의 풀인 **가용 프레임 리스트**를 유지한다.
    
    ![image](https://user-images.githubusercontent.com/87460638/236807389-01977e78-0656-4bb1-bed7-1966152dce84.png)
    

- 프로세스의 스택 또는 힙 세그먼트가 확장될 때도 가용 프레임이 할당되어야 한다.
    - 운영체제는 일반적으로 **zero-fill-on-demand**라는 기법을 사용하여 가용 프레임을 할당한다.
    - **zero-fill-on-demand** 프레임은 할당되기 전에 “0으로 모두 채워져” 이전 내용이 지워진다.

- 시스템이 시작되면 모든 가용 메모리가 가용 프레임 리스트에 넣어진다.
    - 가용 프레임이 요청되면 가용 프레임 리스트의 크기가 줄어진다.

### 10.2.3 요구 페이징의 성능

- 요구 페이징은 컴퓨터 시스템에서 성능에 중요한 영향을 줄 수 있다.
    - 왜 그런지는 **실질 접근 시간**을 계산해보면 알 수 있다.

> **실질 접근 시간 구하기**
> 
- 메모리 접근 시간 = ma
- 페이지 폴트의 확률 = p (0≤ p ≤ 1)
    - p는 0에 가까울 수록 페이지 폴트가 많이 발생하지 않는다.

<aside>
💡 **실질 접근 시간 = (1 - p) x ma + p x (페이지 폴트 시간)**

</aside>

- 페이지 폴트 처리 시간은 다음 3개의 주요 작업 요소로 이루어진다.
    1. 인터럽트 처리
    2. **페이지 읽기**
    3. 프로세스 재시작
    
    ⇒ 이 중에서 페이지를 읽는 시간이 **가장 오래걸리기 때문에 처리 시간에 영향을 많이 준다.**
    
    Ex) 평균 페이징 시간을 8ms, 메모리 접근 시간을 200ns 라고 한다면,
    
    실질 접근 시간 
    
    = (1-p) x 200 + p x 8,000,000
    
    = 200 + 7,999,800 x p
    

- 위 예시를 보면 알 수 있듯이, ***실제 접근 시간은 페이지 폴트율에 비례한다.***
    - 만약 1000번에 1번 페이지 폴트가 발생한다면
    실질 접근 시간 
    = 200 + 799.8 = 8199.8ns
    = 8.2ms 
    즉, 컴퓨터는 요구 페이징 때문에 40배가 느려진 것이다.
    
    - 만약 성능 저하를 10% 이내로 낮추고 싶다면,
    220 > 200 + 7,999,800 x p
    20 > 7,999,800 xp
    p < 0.0000025
    즉, 399,990번 중 1번 이하의 페이지 폴트가 발생해야 한다.
    
    ⇒ ***따라서 요구 페이징 시스템에서 페이지 폴트 비율을 낮게 유지시키는 것이 상당히 중요하다.***
    

- 요구 페이징의 특성 중 하나는 스왑 공간의 관리이다.
    - 스왑 공간에서의 디스크 입출력은 일반적으로 파일시스템에서의 입출력보다 빠르다.
        - 파일 시스템보다 더 큰 블록을 사용하고, 파일찾기, 간접 할당 방법 등이 사용되지 않기 때문이다.
    - 어떤 시스템은 프로세스를 시작할 때 그 파일 이미지를 스왑 공간으로 복사한 후 요구 페이징을 처리함으로써 보다 나은 페이징 처리율을 얻을 수 있다.
    - 어떤 시스템들은 실행 파일을 스왑 공간에 넣지 않음으로써 스왑 공간의 크기를 줄이기도 한다.
        - 그러나 스왑 공간은 여전히 파일과 관련 없는 페이지 때문에 필요하다.
        - 이러한 메모리를 **익명 메모리**라고 한다.
        - 가장 좋은 절충안이며 여러 시스템에서 사용 중이다.

- 모바일 운영체제는 통상 스와핑을 지원하지 않는다.
    - 대신, 파일 시스템으로부터 요구 페이징을 하고 메모리가 부족하게 되면 응용으로부터 코드와 같은 읽기 전용 페이지들을 방출한다.

## 10.3 쓰기 시 복사

- 첫 명령어가 포함된 페이지를 요구 페이징 함으로써 프로세스를 빠르게 시작할 수 있다.
- `fork()` 시스템 호출을 통해 프로세스를 생성할 때 페이지 공유와 비슷한 기법으로 첫 요구 페이징 조차 생략하는 것이 가능하다.
    - 프로세스 생성 시간을 더 줄일 수 있고,
    - 새로 생성된 프로세스에 새롭게 할당되어야 하는 페이지의 수도 최소화할 수 있다.

- `fork()` 는 부모 프로세스와 똑같은 자식 프로세스를 만들어 준다.
    - 대부분의 자식은 복사된 부모 프로세스의 페이지들로 생성된 주소 공간이 만들어지지마자 exec() 시스템 콜을 한다. → 이렇게 되면 복사해온 페이지들이 쓸모 없어진다 !
    - 따라서 부모의 페이지들을 다 복사해오는 대신 **쓰기 시 복사(COW, Copy On Write)** 방식을 사용한다.

- COW는 자식 프로세스가 시작할 때 부모의 페이지를 공유해서 사용한다.
    - 둘 중 한 프로세스가 공유 중인 페이지를 쓰기(write) 하는 시점에서 페이지의 복사본을 만든다.

![image](https://user-images.githubusercontent.com/87460638/236807530-74d127b6-2b99-43c2-8e45-599bfda6fe14.png)

프로세스 1이 페이지 C를 수정하기 전

![image](https://user-images.githubusercontent.com/87460638/236807562-17edeeaa-b512-45ab-ad22-26c7ce227667.png)

프로세스 1이 페이지 C를 수정한 

- 좌측에서 P1을 fork() 한다면 물리적 메모리를 새로 만들지 않고 새 프로세스는 똑같은 물리 메모리 영역을 참조한다.
    - 우측에서 만약 한 변수에 값을 새로 할당해줘서 값이 바뀐다거나 하는 write를 하는 상황이 생긴다면 그 부분의 페이지를 그때 복사해서 다른 물리 메모리 영역을 참조하는 것이다.

## 10.4 페이지 교체

- 페이지 폴트율에 대한 논의에서 각 페이지는 처음 그 페이지가 접근될 때 한번만 페이지 폴트가 발생한다고 가정하였으나, 이는 정확한 것이 아니다 !

- 다중 프로그래밍 정도를 더 올리면, **메모리 과할당**이 발생한다.
- 더욱이 시스템 메모리는 프로그램 페이지를 저장하는 용도로만 사용되는 것이 아니라, 얼마만큼의 메모리를 I/O 용도로 할당하고, 프로그램에 할당하는 가에 따라서 달라질 수 있다.

![image](https://user-images.githubusercontent.com/87460638/236807590-41da3827-1e06-4693-817c-e4dfccaf3c44.png)

- 프로세스가 실행되는 동안 페이지 폴트가 발생한다.
- 운영체제는 필요로 하는 페이지가 보조저장장치에 저장된 위치를 알아내지만 가용된 프레임 목록에 가용한 프레임이 없음을 발견한다.
    
    ⇒ 즉, 모든 메모리가 사용 중인 상황이다. (이를 그림에선 ? 로 표시되어 있다.)
    
- 위 시점에서 운영체제는 몇 가지 선택할 수 있는 방법이 있는데, 그 중 하나가 **페이지 스와핑과 페이지 교체를 결합**하는 것이다.

### 10.4.1 기본적인 페이지 교체

![image](https://user-images.githubusercontent.com/87460638/236807614-940b92b2-3840-4f20-8c40-394568f6671a.png)

> **빈 프레임이 없다면, 현재 사용되지 않는 프레임을 찾아 비워야 한다.**
> 

페이지 교체 과정은 다음과 같다.

1. 보조저장장치에서 필요한 페이지의 위치를 알아낸다.
2. 빈 페이지 프레임을 찾는다.
    1. 비어있는 프레임이 있다면 → 그것을 사용 !
    2. 비어있는 프레임이 없다면 → **희생될 프레임**을 설정하자 ! → **페이지 교체 알고리즘** 가동 !
    3. 희생될 페이지를 보조저장장치에 기록하고, 관련 테이블 수정
3. 빼앗은 프레임에 새 페이지를 읽어오고 테이블을 수정한다.
4. 페이지 폴트가 발생한 지점에서부터 프로세스를 계속한다.

- 페이지 교체는 요구 페이징의 기본이다.
    - 이를 통해 논리적 메모리와 물리 메모리 간의 분리가 완성된다.
    - 이 기법을 통해 매우 작은 메모리도 프로그래머에게 광대한 가상 메모리를 제공할 수 있다.
    
- 요구 페이징 시스템은 두 가지 중요한 문제를 해결해야 하는데, 그것은 **프레임 할당 알고리즘과 페이지 교체 알고리즘**이다.
    - 즉, 여러 프로세스가 존재하는 경우 각 프로세스에 얼마나 많은 프레임을 할당해야 할지 결정해야 한다.
    - 이것이 중요한 이유는 보조저장장치 I/O가 매우 비용이 많이 들기 때문이다.
    - 따라서 요구 페이징 방법은 조금만 개선해도 시스템의 전체 성능이 크게 향상될 수 있다.

- 페이지 교체 알고리즘의 성능은 특정 메모리 참조 나열에 대해 알고리즘을 적용하여 페이지 폴트 발생 횟수를 계산하여 평가한다.
    - 성능의 평가는 ***페이지 부채율이 낮을수록 좋은 알고리즘***이며,
    - 이것을 평가하기 위해서 **참조열(reference string)** 을 사용한다.
    - 참조열은 인공적으로 생성하거나 주어진 시스템의 메모리 참조 주소를 기록하여 생성할 수 있다.
    
    Ex) 특정 프로세스의 참조 주소 추적
    
    ![image](https://user-images.githubusercontent.com/87460638/236807714-40c6b8c1-bbdc-4686-a79b-392d97e095a7.png)
    
    - 페이지 크기가 100바이트라면 → 참조열은 아래와 같다.
    
    ![image](https://user-images.githubusercontent.com/87460638/236807744-5d6610cf-625c-4a8c-a194-b54595ff1e24.png)
    
    - 만약 위 참조열에서 3개 이상의 프레임을 가지면 각 페이지의 첫 번째 참조 때마다 한번씩, 3번의 페이지 폴트만이 발생한다.
    
- 페이지 폴트 횟수를 알고자 하면 프로세스가 사용할 수 있는 페이지 프레임의 수를 알 필요가 있다.
    - **프레임 수가 많으면 페이지 폴트 횟수가 감소할 것이다.**

![image](https://user-images.githubusercontent.com/87460638/236807766-eaab6847-5f05-44f2-90d1-001d6d31c0f6.png)

> 모든 운영체제는 독특한 페이지 교체 기법을 가지고 있다.
일반적으로 **가장 낮은 페이지 폴트 비율을 얻을 수 있는 방향으로 선정**한다.
> 

### 10.4.2 FIFO 페이지 교체

- 가장 간단한 페이지 교체 알고리즘은 FIFO 알고리즘이다.
    - **FIFO는 가장 먼저 들어온 오래된 페이지를 page out 시킨다.**
- 큐를 사용할 땐, 큐의 머리 부분 페이지를 교체하고, 새로 올라온 페이지는 큐의 끝에 삽입하면 된다.
- 장점: 이해하기 쉽고, 프로그램하기도 쉽다.

![image](https://user-images.githubusercontent.com/87460638/236807790-532e4ff1-fa44-49c6-9b19-ddb43ebec172.png)

- 그러나 아래 그래프처럼 상식 밖의 현상이 일어날 수 있다.

![image](https://user-images.githubusercontent.com/87460638/236807818-8c56793a-9078-40f0-8287-a6179543602d.png)

⇒ 이러한 현상을 **Belady의 모순**이라고 한다.

- 이는 프로세스에 프레임을 더 주었는데 오히려 페이지 폴트율은 더 증가하는 현상을 말한다.

⇒ 따라서 ***프로세스에 더 많은 프레임을 할당한다고 해서 항상 성능이 좋아지는 것은 아니다 !***

### 10.4.3 최적 페이지 교체

- Belady의 모순이 가져온 결과 중 하나이다.
- **최적 교체 정책**은 모든 알고리즘보다 낮은 페이지 페이지 폴트율을 보인다.
    - Belady 모순을 일으키지 않는다.
    - **OPT** 또는 **MIN** 이라 불리며, 이것을 요약하면 “**앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체한다.**”와 같다.
    

![image](https://user-images.githubusercontent.com/87460638/236807851-f26355ed-47c0-44b8-b7fa-720a29074544.png)

> 동작 설명
> 
> - 페이지 테이블에 있는 페이지 외의 다른 페이지가 참조될 경우 → 가장 뒤늦게 참조되는 페이지와 교체한다.
>     - ex) 페이지 4를 참조하기 위해 가장 뒤늦게 18번째에 다시 참조되는 페이지 7와 교체한다 !

- 현실적으로 최적 페이지 교체 알고리즘은 구현하기 어렵다.
    - 프로세스가 앞으로 메모리를 어떻게 참조할 것인지를 미리 알아야 하기 때문이다.
    - 주로 비교 연구 목적을 위해 사용된다.

### 10.4.4 LRU 페이지 교체

- 최적 알고리즘이 불가능하더라도 근사 알고리즘 가능할 수 있다.
    - FIFO와 OPT 알고리즘의 결정적 차이는
    - FIFO는 페이지가 메모리로 들어온 시간을 이용하고,
    - OPT는 페이지가 사용될 시간을 이용한다.
    
- 최근의 과거를 가까운 미래의 근사치로 보고, 가장 오랜 기간 동안 사용되지 않은 페이지를 교체할 수 있다.
    - 이 기법이 **LRU(Least-recently-used) 알고리즘** 이다.
    
    ![image](https://user-images.githubusercontent.com/87460638/236807914-cde1a094-10b5-4b77-b127-71bcaa9678c1.png)
    

> 동작 설명
> 
> - 최적의 알고리즘과 동일하게 진행하다가
> - 페이지 테이블 외의 다른 페이지 번호가 참조될 경우 → **가장 오랫동안 사용하지 않는 페이지와 교체한다.**
>     - ex) 페이지 2를 참조할 때, 가장 오랫동안 사용하지 않은 페이지 7과 교체한다.

- 최적 교체와 마찬가지로 LRU 교체는 **Belady의 모순 현상을 야기하지 않는다.**
    - **LRU 정책은 페이지 교체 알고리즘으로 자주 사용되며 좋은 알고리즘으로 인정받고 있다.**
- LRU 페이지 교체 알고리즘의 문제는 **어떻게 알고리즘을 구현하느냐 하는 것**이다.
    - LRU 알고리즘은 **하드웨어의 지원이 필요**하다.
        - 계수기 or 스택 사용

- **계수기 사용**
    - 가장 간단한 방법으로, 각 페이지 항목마다 사용 시간 필드를 넣고 CPU에 논리 클럭이나 계수기를 추가한다.
    - **메모리가 접근될 때마다 시간은 증가하고, 페이지에 대한 참조가 일어날 때마다 페이지의 사용 시간 필드에 시간 레지스터의 내용이 복사된다.**
    
    ⇒ 이렇게 각 페이지의 마지막 참조 시간을 유지할 수 있다.
    
- **스택 사용**
    - LFU 교체 정책의 다른 구현 방법은 **페이지 번호의 스택을 유지**하는 방법이다.
    - **페이지가 참조될 때마다 페이지 번호는 스택 중간에서 제거되어 스택 꼭대기(top)에 놓이게 된다.**
    
    ⇒ 이렇게 하면 스택의 꼭대기는 항상 가장 최근에 사용된 페이지고, 밑바닥(bottom)은 가장 오랫동안 이용되지 않은 페이지이다.
    

### 10.4.5 LRU 근사 페이지 교체

- LRU 페이지 교체 지원을 충분히 할 수 있는 하드웨어는 많지 않다.
    - 그러나 많은 시스템은 **참조 비트**의 형태로 어느 정도의 하드웨어 지원을 하고 있다.
    1. 부가적 참조 비트 알고리즘
    2. 2차 기회 알고리즘
    3. 개선된 2차 기회 알고리즘 

**10.4.5.1 부가적 참조 비트 알고리즘**

- 각 페이지에 대해 8비트의 참조 비트를 할당해 기록함으로써 추가적인 선후 관계 정보를 얻을 수 있다.
    - 타이머 인터럽트를 걸어서 운영체제가 참조 비트를 8비트 정보의 최상위 비트로 이동시키고, 나머지 비트들은 하나씩 오른쪽으로 이동시킨다.
    - 이 8비트 값을 정수로 생각하면 **가장 작은 수를 갖는 페이지가 LRU 페이지가 된다.**

- 이 알고리즘의 극단적인 경우,
    - 비트수가 0이 될 때 참조 비트만 남게 되는 경우가 발생한다.
    - ⇒ 이 알고리즘을 **2차 기회 알고리즘**이라고 한다.

**10.4.5.2 2차 기회 알고리즘**

- 2차 기회 알고리즘의 기본은 FIFO 교체 알고리즘이다.
    - 그러나 페이작 선택될 때마다 참조 비트를 확인한다.
    - 참조비트가 0이면 → **페이지 교체**
    참조비트가 1이면 → 다시 한번 기회를 주고 **다음 FIFO 페이지로 넘어간다.**

- 2차 기회 알고리즘 구현하는 방법 중 하나가 **순환 큐**를 이용하는 것이다.
    - 이 큐에는 포인터가 있어서 다음에 교체될 페이지를 가리킨다.
    - 어떤 프레임을 빼앗아야 할 일이 생기면, 포인터는 0값의 참조 비트를 가진 페이지를 발견할 때까지 큐를 찾는다.
    - 포인터가 돌아가면서 참조 비트값이 1이면 0으로 바꾼다.
    - 희생될 페이지인 0을 찾으면 → 그 페이지는 교체되고, 새로운 페이지는 순환 큐의 해당 위치에 삽입된다.

![image](https://user-images.githubusercontent.com/87460638/236807983-88c2a0e1-44c9-4682-a634-6663eedb4977.png)

- 참조 비트와 변경 비트를 사용하면 더 개선할 수 있다.
    - 이 알고리즘을 **개선된 2차 기회 알고리즘** 이라고 부른다.

**10.4.5.3 개선된 2차 기회 알고리즘**

- 참조 비트와 변경 비트를 조합하여 사용하면 다음 4가지 등급이 가능하다.
    1. 최근에 사용되지도 변경되지도 않은 경우
    2. 최근에 사용되진 않았지만 변경은 된 경우
    3. 최근에 사용되었으나 변경은 되지 않은 경우
    4. 최근에 사용과 변경도 된 경우
    
    ⇒ 각 페이지는 이 등급 4가지 중 하나에 속한다.
    

### 10.4.6 계수-기반 페이지 교체

- 각 페이지를 참조할 때마다 counting 하여 다음과 같은 2가지 기법을 만들 수 있다.
- **LFU 알고리즘 (Least Frequently Used)**
    - LFU 알고리즘은 참조 횟수가 가장 작은 페이지를 교체하는 방법이다.
- **MFU 알고리즘 (Most Frequently Used)**
    - MFU 알고리즘은 가장 작은 참조 횟수를 가진 페이지가 가장 최근 참조된 것이고, 앞으로 사용될 것이라는 판단에 근거한 것이다.

- 위 두 알고리즘은 일반적으로 잘 쓰이지 않는다.
    - 구현하는 데 상당한 비용과 최적 페이지 교체 정책을 제대로 근사하지 못하기 때문이다.

### 10.4.7 페이지-버퍼링 알고리즘

- 페이지 교체 알고리즘과 병행하여 여러 가지 버퍼링 기법이 사용될 수 있다.

1. **시스템들이 가용 프레임 여러 개를 풀(pool)로 유지하는 방법**
- 페이지 폴트가 일어나면 희생될 프레임으로 선택될 페이지는 디스크로 기록되기 전에 가용 프레임으로 들어간다.
- 희생된 페이지가 나가기를 기다리지 않고 프로세스가 가능한 한 빨리 시작할 수 있도록 해준다.
- 교체될 페이지가 다 쓰이고 나면 그 프레임이 가용 프레임 풀에 추가된다.

1. **변경된 페이지들의 리스트 유지하는 방법 (1번 방법의 확장편)**
- 페이징 장치가 쉬는 동안 변경된 페이지를 선택하여 디스크에 기록하고 변경 비트를 0으로 설정한다.
- 페이지 교체를 위해 선택될 때 페이지가 변하지 않았을 가능성을 높인다.

1. **가용 프레임 유지하면서 풀 속 각 프레임의 원래 페이지를 기억하는 방법**
- 페이지 폴트가 일어날 때 찾는 페이지가 아직도 풀에 훼손되지 않은 채로 남아 있는지 검사한 후, 만약 없으면 그때 페이지를 읽어 들인다.

### 10.4.8 응용과 페이지 교체

- 몇몇 경우에, 운영체제의 가상 메모리를 통해 데이터에 접근하는 응용이 운영체제가 전혀 버퍼링 기능을 제공하지 않는 경우에 오히려 안좋은 성능을 보일 때가 있다.
    - ⇒ 이러한 문제들 때문에 몇몇 운영체제에는 순차적 배열인 **raw disk** 기능을 갖추고 있다.

## 10.5 프레임의 할당

### 10.5.1 최소로 할당해야 할 프레임의 수

- 메모리 할당에는 **제한이 있어서 총 가용 프레임 수보다 더 많이 할당할 수 없다.**
    - 하지만 할당 가능한 최소의 프레임은 있다. → **최소한의 페이지는 할당해야만 한다 !**

- 최소한의 프레임을 할당해야 하는 이유
    - 프로세스에 할당되는 프레임의 수가 줄어들면 페이지 폴트율은 증가하고 프로세스 실행은 늦어지게 된다.
    - 명령어 수행이 완료되기 전에 페이지 폴트가 발생하면 그 명령어를 재실행해야 한다.

- 프로세스당 필요한 최소 프레임 수는 아키텍처에 의해 정의된다.
    - 최대 수는 사용 가능한 물리 메모리 양에 의해 정의된다.
    - 단 하나의 주소만을 가지는 기계라면 → 프로세스 당 최소 2개 프레임이 필요하다.
    - 간접 주소 지정이 가능할 경우 → 프로세스 당 최소 3개의 프레임이 필요하다.

### 10.5.2 할당 알고리즘

- n개의 프로세스에 m개의 프레임을 분할하는 가장 쉬운 방법은 모두에게  프레임을 m/n의 몫으로 균등하게 할당하는 것이다.
    - 남은 가용 프레임은 버퍼 저장소로 사용한다.
    - ⇒ 이를 **균등 할당**이라 한다.

- 프로세스의 크기 비율에 맞춰 각 프로세스에게 프레임을 할당하는 방법도 있다.
    - ⇒ 이를 **비례 할당**이라 한다.

ex) 62개 프레임을 10 크기의 페이지 프로세스와 127 크기의 페이지 프로세스가 있다고 한다면,

- 균등 할당 : 각 프로세스에 31개 프레임
- 비례 할당
    - 10 페이지 프로세스 : 10 / (127 + 10) x 62 = 4개 프레임
    - 127 페이지 프로세스 : 127 / (127 + 10) x 62 = 57개 프레임

- 여기서 유의해야할 점은 균등 할당과 비례 할당 모두 **우선순위를 고려하지 않고 있다 !**
    - 우선 순위가 높은 프로세스에 많은 기억 장소를 할당하여 수행 속도를 높이는 것이 바람직 하다.
    - 따라서 이에 대해 해결책은
    (1**) 비례 할당법을 사용하되** 할당하는 프레임 수를 프로세스의 상대적 크기가 아닌 **우선 순위를 고려하거나** 
    (2) **둘 모두를 고려**하도록 하거나 
    (3) 우선 순위가 높은 프로세스가 **교체할 프레임을 우선 순위가 낮은 프로세스에 할당**되 프레임 중에서 선택하게 한다.

### 10.5.3 전역 대 지역 할당

- 프레임을 할당하는 방법에서 중요한 또 한가지 요소는 **프레임 할당을 위해 경쟁하는 환경**이다.
    - 이는 **전역 교체와 지역 교체**로 나눌 수 있다.

- **전역 교체**
    - 프로세스가 교체할 프레임을 다른 프로세스에 속한 프레임을 포함한 모든 프레임을 대상으로 찾는 경우이다.
    - 한 프로세스에 할당된 프레임의 수는 변할 수 있다.
- **지역 교체**
    - 각 프로세스가 자기에게 할당된 프레임 중에서만 교체될 희생자를 선택하는 경우이다.
    - 프로세스에 할당된 프레임의 수는 변하지 않는다.

- 전역 교체 알고리즘의 문제점은 프로세스의 메모리에 있는 페이지 집합이 해당 프로세스의 페이징 동작 뿐만 아니라 다른 프로세스의 페이징 동작에도 영향을 받는다는 것이다.
    - 따라서 동일한 프로세스도 그때그때 외부적 환경에 따라서 전혀 다르게 실행될 수 있다.

- 아래 그림은 전역 페이지 교체 정책을 구현하는 데 사용할 수 있는 전략 중 하나이다.
    - 이 전략의 목적은 **가용 메모리 양을 최소 임계값 이상으로 유지하는 것**이다.
    - 최소 임계값 아래로 떨어지면 → 시스템의 모든 프로세스에서 **페이지를 회수하기 시작**하는 커널 루틴이 촉발된다.
        - 이러한 커널 루틴을 **리퍼(reaper)**라고 한다.
    - 최대 임계값에 도달하면 → **리퍼 루틴이 일시 중단**되며, **다시 아래로 떨어지게 된다.**

![image](https://user-images.githubusercontent.com/87460638/236808034-a244faea-f25b-4143-aab4-8e148fcf9154.png)

- 커널 리퍼 루틴은 임의의 페이지 교체 알고리즘을 채택할 수 있으나, 일반적으로 LRU 근사 형태의 알고리즘을 사용한다.
    - 만약 리퍼 루틴이 가용 프레임 리스트를 최소 임계값 이상으로 유지할 수 없는 경우가 발생한다면,
        - 운영체제는 FIFO를 사용할 수 있다.
        - (극단적인 경우) 메모리 사용 가능양이 매우 낮은 수준으로 떨어지면 
        → **메모리-부족 (OOM, Out-Of-Memory) 킬러**라고 하는 루틴이 종료할 프로세스를 선택하여 메모리를 회수한다,
    
     
    

### 10.5.4 비균등 메모리 접근

- **비균등 메모리 접근(NUMA)** 시스템은 특정 CPU가 메인 메모리의 일정 영역에 다른 영역보다 빠르게 접근할 수 있다.
    - 이러한 시스템은 각각 자신의 로컬 메모리가 있는 여러 CPU로 구성된다.
    
    ![image](https://user-images.githubusercontent.com/87460638/236808072-e58bfac8-ba5b-4d22-b3f9-9eec706b4d99.png)
    
    - CPU는 공유 시스템 상호 연결을 사용하여 구성되며,
    - 다른 CPU의 로컬 메모리보다 자신의 로컬 메모리에 빠르게 액세스 할 수 있다.

- NUMA 시스템은 메인 메모리에 대한 모든 액세스가 동일하게 취급되는 시스템보다 느리다.
    - 그러나 **더 많은 CPU를 수용**할 수 있어 ⇒ **더 많은 처리량과 병렬 처리**를 할 수 있다.

- CPU가 메모리에 접근할 대 대기 시간이 매우 길어질 수 있다.
    - ⇒ 이러한 모든 수정의 목표는 “**프로세스가 실행 중인 CPU에 가능한 가장 가까운**” 메모리 프레임이 할당되도록 하는 것이다.
    - ‘***가까운***’ 의 정의는 “**최소 지연 시간을 가진**”을 의미한다.

- NUMA를 고려하면 스케줄러는 프로세스가 마지막으로 실행된 CPU를 추적해야 한다.
    - 스케줄러는 각 프로세스를 직전에 실행된 CPU에 스케줄하고, 가상 메모리 시스템은 스케줄 된 CPU와 가까운 프레임을 할당한다면 → 캐시 적중률이 높아지고 메모리 접근 시간이 감소하게 될 것이다.

## 10.6 스레싱

- 프로세스가 실제로 사용하는 프레임 수만큼의 프레임을 가지지 못해 계속적으로 페이지 폴트가 발생함으로 인해 계속적으로 페이지 교체가 발생한다.
    - 이러한 과도한 페이징 작업을 **스레딩(thrashing)** 이라고 부른다.
    - **프로세스가 실제 실행보다 더 많은 시간을 페이징에 사용하고 있을 때** “스레싱이 발생했다” 고 한다.

### 10.6.1 스레싱의 원인

- 운영체제는 CPU의 이용률을 감시한다.
    - CPU 이용률이 너무 낮아지면 
    → CPU 스케줄러는 새로운 프로세스를 **시스템에 더 추가해서 다중 프래그래밍의 정도를 높인다.**
    - 그러나 이것이 반복되면 오히려 **CPU 이용률이 더욱 떨어지고 CPU 스케줄러는 다중 프로그래밍 정도를 더욱 높이려고 하면서** 결국 **스레싱이 일어나게 된다.**
    
    ![image](https://user-images.githubusercontent.com/87460638/236808119-d9fb556a-b76f-44a7-97d9-562097fd0274.png)
    
    다중 프로그래밍 정도에 따른 CPU 이용률의 그래프
    
- 다중 프로그래밍의 정도가 높아짐에 따라 CPU의 이용률이 높아지다가 스레싱이 일어나면 CPU 이용률이 급격히 저하한다.
    - 프로세스 실행보다 페이지 교체에 보내는 시간이 더 크기 때문

***⇒ 따라서 스레싱이 일어나는 시점에서는 반대로 다중 프로그램 정도를 낮춰야 한다.***

- **지역 교체 알고리즘**(or **우선순위 교체 알고리즘**)을 사용하여 스래싱의 영향을 제한할 수 있다.
    - ⇒ 그러나 문제가 완전히 해결되진 않는다 !

- 스래싱 현상을 방지하기 위해서는 **각 프로세스가 필요로 하는 최소한의 프레임 개수를 보장해야 한다.**
    - 어떻게 각 프로세스가 필요로 하는 최소한의 프레임 수를 알 수 있지 ?
        
        ⇒ **지역성 모델**을 기반으로 프로세스 실행한다. 
        
- **지역성 모델**은 프로세스가 실행될 때에는 항상 어떤 특정한 지역에서만 메모리를 집중적으로 참조함을 말한다.
    - 여기서 **지역(locality)**이란, 집중적으로 함께 참조되는 페이지들의 집합을 말한다.
    - 실행 중인 프로그램은 여러 개의 지역으로 구성되어 있고, 이 지역들은 서로 겹쳐질 수 있다.

- 아래 그림은 지역성의 개념과 시간이 지남에 따라 프로세스의 지역성이 어떻게 변하는지를 보여준다.

![image](https://user-images.githubusercontent.com/87460638/236808145-37840e5c-dac2-4397-a5c3-d86a7fb68b15.png)

### 10.6.2 작업 집합 모델

- **작업 집합 모델**은 지역성을 토대로 하고 있다.
    - **작업 집합(window)**을 가지고 있는데,
    - 이는 한 프로세스가 최근 x만큼의 페이지를 참조했다면 그 안에 있에 들어있는 서로 다른 페이지들의 집합을 **작업집합**이라고 부른다.
    - 간단히 요약하면, **프로그램 지역성의 근삿값**을 말한다.

![image](https://user-images.githubusercontent.com/87460638/236808201-016a9c11-ac00-4f34-86f5-dc7d7256ca45.png)

- 이 모델의 가장 중요한 요소는 집합의 크기이다.
    - 각 프로세스가 **WSS만한 크기의 공간을 작업 집합의 크기**로 요구한다면, 모든 프로세스 **전체의 요구량 D**는 다음과 같다.
    
    $$
    D = ∑WSS_ip
    $$
    
    - **D > m (m = 총 메모리 크기)이면 → 스레싱이 발생한다.**
        
        ⇒ 해결법: 중지시킬 프로세스를 하나 선택해서 모든 페이지를 내보내고 프레임을 다른 프로세스에 할당한다.
        

### 10.6.3 페이지 폴트 빈도

- 작업 집합 모델은 선페이징 시에는 유용하지만 스래싱 조절하는 방법으로는 아쉬운 방법이다.
    - **페이지 폴트 빈도(PFF)** 방식은 이보다 더 직접적으로 스래싱을 조절한다.

- **스래싱은 페이지 폴트율이 높은 것을 의미한다 !**
    
    ![image](https://user-images.githubusercontent.com/87460638/236808404-418e4080-629b-409e-a6f4-6aba50300613.png)
    
    - 우리는 페이지 폴트율을 조절하기 위해 페이지 폴트율의 상한과 하한을 정해 놓고,
    - 페이지 폴트율이 상한을 넘으면 → 해당 프로세스에 **프레임을 더 할당**하고,
    - 페이지 폴트율이 하한보다 낮으면 → 해당 프로세스의 **프레임 수를 줄인다.**
    
    ⇒ 이렇게 함으로써 ***직접적으로 부재율을 관찰하고 조절할 수 있어 스래싱을 방지할 수 있다.***
    

- 만약 프로세스를 스왑아웃 해야만 할 경우,
    - 페이지 폴트율이 높아졌다면(즉, 가용 프레임이 없다면) 
    → 한 프로세스를 선택해서 그 프로세스를 예비 저장장치로 스왑아웃 시킨다.
    
    ⇒ 이렇게 되면 ***할당되었던 프레임은 높은 페이지 폴트율을 갖는 다른 프로세스들에게 분배된다.***
    

<aside>
💡 **작업 집합과 페이지 폴트율**
- 한 프로세스의 작업 집합과 페이지 폴트율 사이에는 직접적인 연관이 있다.
- 프로세스의 **직업 집합을 수용할 수 있는 충분한 메모리가 있다면** (즉, 프로세스가 스래싱 중이 아니면) **페이지 폴트율은 시간이 지남에 따라 고점과 저점 사이를 오르내리게 된다.**

![image](https://user-images.githubusercontent.com/87460638/236808440-24413a89-ff9d-40f2-8ba2-6091c15b70fd.png)

</aside>

## 10.7 메모리 압축

- 페이징의 대안은 **메모리 압축**을 하는 것이다.
    - 메모리 압축은 수정된 프레임을 스왑 공간으로 페이징 아웃하지 않고 **여러 프레임을 하나의 프레임으로 압축하는 것**을 말한다.

![image](https://user-images.githubusercontent.com/87460638/236808489-91064393-9f8e-46be-8c65-90723c0c4554.png)

압축 이전의 가용 프레임 리스트

![image](https://user-images.githubusercontent.com/87460638/236808522-4fe4d159-db45-4742-bdf4-9910dec9cd98.png)

압축 이후의 가용 프레임 리스트

- 메모리 압축을 위해서는 압축된 페이지를 유지하기 위해 사용 가능한 프레임을 할당해야 하지만, 압축 알고리즘으로 얻은 메모리 감소에 따라 상당히 메모리를 절약할 수 있다.
    - 압축 알고리즘의 속도와 감소량 사이에 경합이 있는 것을 **압축률**이라고 부른다.
    - 대부분 알고리즘은 이 두 가지 요소의 균형을 맞춰서 빠른 알고리즘을 사용하여 비교적 높은 압축률을 달성한다.

## 10.8 커널 메모리의 할당

- 커널 메모리는 보통 사용자 모드 프로세스에 할당해 주기 위한 페이지 리스트와는 별도의 메모리 풀에서 할당받는다.
    - 이유는 다음과 같다.
    1. 커널은 다양한 크기의 자료구조를 위해 메모리를 할당받는다. 자료구조들은 페이지 크기보다 작은 크기를 갖기도 하기 때문에 메모리를 조심히 사용해야 하고, 단편화에 의한 낭비를 최소화해야 한다.
    2. 사용자 모드 프로세스에 할당되는 페이지들은 연속적일 필요가 없지만, 물리 메모리에 직접 접근하는 특정 하드웨어 장치는 물리적으로 연속적인 메모리가 있어야 하는 경우가 있다.

⇒ 커널 프로세스에 할당되는 메모리를 관리하는 두 가지 기법을 살펴보자 !

### 10.8.1 버디 시스템

- 버디 시스템은 물리적으로 연속된 페이지들로 이루어진 고정된 크기의 세그먼트로부터 메모리를 할당한다.
    - 메모리는 이 세그먼트로부터 **2의 거듭제곱 할당기**에 의해  2의 제곱 할당기 단위로 할당된다.
    - 2의 거듭제곱 크기가 아닌 메모리 요구는 가장 가까운 2의 거듭제곱 크기로 올림된다.

ex) 메모리 세그먼트의 크기는 초기에 256KB이고, 커널이 21KB의 메모리를 요구한다고 가정하자.

- 세그먼트가 두 개의 **버디(buddies)**로 나눠진다.
- 마지막 버디 중 하나가 커널이 요구한 메모리를 할당해준다.

![image](https://user-images.githubusercontent.com/87460638/236808561-e3de5bf9-8ad0-433f-81d1-43148edde040.png)

- 버디 시스템의 이점 중 하나는 **합병(coalescing)** 과정을 통해 서로 인접한 버디들이 손쉽게 하나의 큰 세그먼트로 합쳐질 수 있다는 점이다.
- 단점은 가장 가까운 2의 거듭제곱으로의 올림이 할당된 세그먼트 내의 단편화를 가져온다.
    - 실제로 할당된 세그먼트의 50% 이하의 메모리만이 내부 단편화에 의해 낭비된다는 것이다.
        - 예를 들어, 33KB 요청은 64KB 세그먼트에 의해 만족하면, 나머지는 낭비가 된다.

### 10.8.2 슬랩 할당

![image](https://user-images.githubusercontent.com/87460638/236808595-aef31564-26b7-4b00-ac9f-3f6ceba69f1e.png)

- **슬랩(slab)**은 하나 또는 그 이상의 연속된 페이지들로 구성된다.
    - **캐시(cache)**는 하나 혹은 그 이상의 슬랩들로 구성된다.
    - 각 커널 자료구조마다 하나의 캐시가 존재한다.

- 슬랩 할당 알고리즘은 커널 객체를 저장하기 위해 캐시를 사용한다.
    - 캐시가 생성되면 초기에는 **free**라고 표시된 몇 개의 객체들이 캐시에 할당된다.
    - 커널 자료구조를 위한 객체가 필요하면 free 객체 중 하나를 캐시로부터 할당하고 **used** 라고 표시한다.
    
- 슬랩은 **Full, Empty, Partial** 중 한 상태에 있게 된다.
- 슬랩 할당기는
    - 먼저 partial 슬랩의 free 객체를 이용해 요청을 처리하려고 시도한다.
    - Partial 슬랩이 없으면 → empty 슬랩으로부터 free 객체를 할당한다.
    - Empty 슬랩도 없으면 → 새로운 슬랩이 연속된 물리 메모리에서 할당되어 캐시에 주어진다.

- 슬랩 할당기에는 2가지 장점이 있다
    1. 단편화에 의해 낭비되는 메모리가 없다. 즉, 커널이 메모리 할당을 요구할 때마다 슬랩 할당기는 정확히 필요한 만큼의 메모리만을 할당한다.
    2. 메모리 요청이 빠르게 처리된다. 따라서 할당과 해제가 빈번한 자료 구조 객체를 관리하는 데 특히 효율적이다.

## 10.9 기타 고려 사항

### 10.9.1 프리페이징

- 프리페이징은 높은 수준의 초기 페이징을 방지하려는 시도이다.
    - 이 전략은 필요한 페이지의 일부 or 전부를 한 번에 메모리에 가져오는 것이다.

- 프리페이징은 때에 따라 이점을 제공할 수 있다.
    - 문제는 단순히 프리페징을 사용하는 비용이 해당 페이지 폴트를 처리하는 비용보다 적은지 여부이다.
        - 프리페이징의 의해 메모리로 가져온 많은 페이지가 사용되지 않는 경우가 있다.
        

### 10.9.2 페이지의 크기

- 이미 존재하는 시스템의 운영체제의 페이지 크기를 바꾸는 것은 거의 불가능하다.
    - 그러나 새 시스템을 개발할 때는 페이지 크기를 결정해야 한다.

- 모든 활성 프로세스는 각자의 페이지 테이블을 유지해야 하므로 큰 페이지가 좋다.
    - 그러나 할당해 준 메모리 사용 효율을 위해서는 작은 페이지가 좋다.

### 10.9.3 TLB Reach

- **TLB reach**는 TLB로부터 액세스할 수 있는 메모리 공간의 크기를 말한다.
    - 이상적으로는 한 프로세스의 작업 집합이 TLB에 다 들어올 수 있으면 가장 좋다.
    - 그렇지 못한다면 프로세스는 수행하면서 매우 많은 메모리 참조를 TLB에서 해결하지 못하고 페이지 테이블까지 가야만 하기 때문에 수행 시간이 매우 느려지게 된다.

### 10.9.4 역 페이지 테이블

- 역 페이지 테이블의 목적은 가상-물리 주소 변환을 추적하는 데 필요한 물리 메모리의 양을 줄이는 것이다.
    - <process-id, process-number>에 의해 색인되며, 각 물리 메모리마다 한 항목을 갖는다.
