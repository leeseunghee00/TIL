## Intro
- CPU 스케줄링은 CPU 이용률과 사용자에게 제공하는 컴퓨터 응답속도를 모두 향상할 수 있다.
    - 이러한 성능 향상을 실현하려면 많은 프로세스를 메모리에 유지해야 한다.
    - 즉, **메모리를 공유해야 한다.**

⇒ 따라서 이 장에서는 메모리를 관리하는 다양한 방법에 대해 알아보자.

## 9.1 배경

![image](https://user-images.githubusercontent.com/87460638/235685315-71c097d1-41bf-4c34-974b-2f08640fa29d.png)

- 전형적인 명령어 실행은
    - 메모리로부터 명령어를 **가져오고**
    - 명령어를 **해독**하고
    - 메모리에서 피연산자를 가져와 이에 대해 명령어를 **실행**한 후
    - 계산 결과를 메모리에 다시 **저장**한다.
- 메모리는 주소에서 지시한 대로만 할 뿐 이 주소들이 어떻게 생성되었는지 혹은 그 주소가 가리키는 내용이 무엇인지 모른다.

⇒ 따라서 프로그램에 의해서 생성되는 일련의 주소부터 알아보자.

### 9.1.1 기본 하드웨어

- CPU가 직접 접근할 수 있는 범용 저장장치는 **메인메모리와 각 처리 코어에 내장된 레지스터들**이다.
    - ***기계 명령어들은 메모리 주소만을 인수로 취하기 때문에*** 모든 명령어와 데이터들은 CPU가 직접 접근할 수 있는 메인 메모리와 레시스터에 있어야 한다.

- CPU 코어에 내장된 레지스터들은 일반적으로 CPU 클록의 1사이클 내에 접근이 가능하다.
    - 일부 처리 코어들은 레지스터에 있는 명령어의 해독과 간단한 연산을 **클록 틱(clock tick)당 하나 또는 그 이상의 속도로 처리한다.**
    - 그러나 메모리 버스를 통해 전송되는 메인 메모리의 경우는 상황이 다르다.
- 메인 메모리의 접근을 완료하기 위해서는 많은 CPU 클록 틱 사이클이 소요되며, 이 경우 CPU가 필요한 데이터가 없어서 명령어를 수행하지 못하고 **지연되는(stall) 현상**이 발생한다.
    - 해결방법: CPU와 메인 메모리 사이에 빠른 속도의 메모리 즉, **캐시를 추가하는 것**이다.
        
        ⇒ **하드웨어는 운영체제 도움 없이 메모리 접근 속도를 향상한다.**
        
- 시스템이 올바르게 동작하기 위해서는 사용자 프로그램으로부터 운영체제 영역을 보호해야 할 뿐만 아니라 사용자 프로그램 사이도 서로 보호해야 한다.
    - 운영체제가 CPU와 메모리 간의 접근 중에 개입하게 되면 성능이 떨어지기 때문이다.
    - 따라서 이러한 보호 기법은 반드시 하드웨어가 지원해야 한다.

- **각각의 프로세스가 독립된 메모리 공간을 가지도록 보장해야 한다.**
    - 아래 그림과 같이 개별적인 메모리 공간을 분리하기 위해 특정 프로세스만 접근할 수 있는 합법적인(legal) 메모리 주소 영역을 설정하고, 프로세스가 합법적인 영역만을 접근하도록 하는 것이 필요하다.
    
    ![image](https://user-images.githubusercontent.com/87460638/235685379-a17573cf-f0f8-4eda-98c4-75a3b765f549.png)
    
    - 기준(base) 과 상한(limit) 레지스터를 사용하여 보호 기법을 제공한다.
        - **기준 레지스터**는 가장 작은 합법적인 물리 메모리 주소의 값을 저장한다.
        - **상한 레지스터**는 주어진 영역의 크기를 저장한다.

- 메모리 공간의 보호는 CPU 하드웨어가 사용자 모드에서 만들어진 모든 주소와 레지스터를 비교함으로써 이루어진다.
    
    ![image](https://user-images.githubusercontent.com/87460638/235685427-8f73bb25-9057-4c1b-bf3d-1c6bce741e4e.png)
    
    - 사용자 모드에서 수행되는 프로그램이 운영체제의 메모리 공간이나 다른 사용자 프로그램의 메모리 공간에 접근하면 운영체제는 치명적인 오류로 간주하고 **트랩(trap)을 발생**시킨다.
    - 이러한 기법은 사용자 프로그램이 운영체제나 다른 사용자 프로그램의 코드나 데이터 구조를 수정하는 것을 막는다.

- 기준과 상한 레지스터는 여러 가지 특권 명령을 사용하는 운영체제에 의해서만 적재(load)된다.
    - 왜냐하면 특권명령은 오직 커널 모드에서만 수행되고, 운영체제만 커널 모드에서 수행되기 때문이다.
    - 이러한 기법은 운영체제만 레지스터들의 값을 변경할 수 있도록 허가해 줌으로써 사용자 프로그램이 레지스터의 내용을 변경하는 것을 막는다.

- 커널모드에서 수행되는 운영체제는 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 어떠한 제약도 받지 않는다.
    - 이러한 원칙 때문에 운영체제는 
    (1) 사용자 프로그램을 사용자 메모리 영역에 적재, 
    (2) 오류가 발생한 경우에 그 프로그램을 덤프(dump out),
    (3) 시스템 콜의 매개변수를 변경,
    (4) 사용자 메모리로부터의 입출력과 다른 많은 서비스를 제공할 수 있다.

### 9.1.2 주소의 할당

- 프로그램은 이진 실행 파일 형태로 디스크에 저장되어 있다가, 실행할 때 프로그램을 메모리로 가져와서 프로세스 문맥 내에 배치한다.
    - 이 시점에 가용한 CPU에서 실행할 수 있다.
    - 프로세스가 실행되면 메모리에서 명령 및 데이터에 액세스 한다.
    - 프로세스가 종료되면 다른 프로세스에서 사용하기 위해 메모리가 회수된다.

- 원시 프로그램에서 주소는 숫자가 아닌 심볼 형태로 표현된다.
- 컴파일러는 이 심볼 주소를 재배치 가능 주소로 바인딩 시킨다.
- 링커나 로더가 재배치 가능 주소를 절대 주소로 바인딩 시킨다.
    - 각각의 바인딩 과정은 한 주소 공간에서 다른 주소 공간으로 맵핑하는 것이다.

![image](https://user-images.githubusercontent.com/87460638/235685496-c012aadf-d483-4e3f-91c9-9a52b9c3f2d5.png)

> ***메모리 주소공간에서 명령어와 데이터의 바인딩은 그 바인딩이 이루어지는 시점에 따라 3가지로 구분된다.***
> 
1. **컴파일 시간 바인딩**

만일 프로세스가 메모리 내에 들어갈 위치를 컴파일 시간에 미리 알 수 있으면 컴파일러는 **절대 코드**를 생성할 수 있다.

ex) 사용자 프로세스가 R번지로부터 시작한다는 것을 미리 알면 컴파일러는 번역할 코드를 그 위치에서 시작해 나간다.

1. **적재 시간 바인딩**

만일 프로세스가 메모리 내 어디로 올라오게 될지를 컴파일 시점에 알지 못하면 컴파일러는 이진 코드를 **재배치 가능 코드**로 만들어야 한다. 이 경우에 심볼과 진짜 번지수와의 바인딩은 프로그램이 메인 메모리로 실제 적재되는 시간에 이루어진다.

1. **실행 시간 (런타임) 바인딩**

만약 프로세스가 실행하는 중간에 메모리 내의 한 세그먼트로부터 다른 세그먼트로 옮겨질 수 있다면 바인딩이 실행 시간까지 허용되었다고 이야기할 수 있다.

### 9.1.3 논리 대 물리 주소 공간

- CPU가 생성하는 주소를 일반적으로 **논리 주소(logical address)** 라 하며, 메모리가 취급하게 되는 주소 즉, 메모리 주소 레지스터(MAR)는 일반적으로 **물리 주소(physical address)** 라 한다.

- 컴파일 or 적재 시에 주소를 바인딩하면 논리 주소와 물리 주소가 같다.
    - 그러나 실행 시간 바인딩 기법은 각각 주소가 다르다.
    - 여기서 논리 주소는 **가상 주소**라고 한다. (논리 주소는 가상 주소로도 불림)
    - 프로그램에 의해 생성된 모든 논리 주소 집합을 **논리 주소 공간**이라 한다.
    - 논리 주소와 일치하는 모든 물리 주소 집합을 **물리 주소 공간**이라 한다.

- 따라서 프로그램 실행 중에 가상 주소를 물리 주소로 바꿔주는 변환 작업을 해야 하는데 이를 하드웨어 장치인 **메모리 관리 장치(MMU)**에 의해 실행된다.

![image](https://user-images.githubusercontent.com/87460638/235685543-fc9d5983-3a85-4a72-900c-d73b0a73bdce.png)

> 이러한 변환을 수행하기 위해 여러 가지 방법 중에서 선택할 수 있다.
하지만 우리는 우선 기준 레지스터 기법을 일반화시킨 단순환 MMU 기법에 따른 변환에 대해 알아보자 !
> 

- 여기서 기준 레지스터는 **재배치 레지스터**라고 부른다.
    - 재배치 레지스터 속에 들어있는 값은 주소가 메모리로 보내질 때마다 그 모든 주소에 더해진다.
    
    ![image](https://user-images.githubusercontent.com/87460638/235685603-e1eaad68-707f-42eb-b5d4-0c7668f8177f.png)
    
    - 예를 들어, 재배치 레지스터 값이 14000 이라면 프로세스가 346번지에 액세스할 때, 실제론 레지스터값 + 프로세스 주소인 14346번지인 메인 메모리에 액세스하게 된다.

- 사용자 프로그램은 절대 실제적인 물리 주소에 접근하지 않는다 !
    - 346번지에 대한 포인터를 생성해 모든 일을 수행 수 있지만, 포인터가 주소로 갈 때는 기준 레지스터에 대해 다시 바인딩된다.
    

<aside>
💡 정리하면, **사용자 프로그램은 논리 주소를 사용한 것**이고, **메모리 하드웨어는 논리 주소를 실제 주소로 바꾼 것**이다.

따라서 ***논리 주소와 실제 주소가 있다는 사실에 유의하여 올바른 메모리 관리를 해야 한다.***

</aside>

### 9.1.4 동적 적재

⚠️ 지금까지의 설명은 프로세스가 실행되기 위해 그 프로세스 전체가 미리 메모리에 올라와야 있어야 하며, 프로세스의 크기는 메모리의 크기보다 커서는 안됐다.

- 그러나 메모리 공간의 더 효율적 이용을 위해선 **동적 적재(dynamic loading)**를 해야 한다.
    - 동적 적재에서 각 루틴은 실제 호출되기 전까지는 메모리에 올라오지 않고 재배치 가능한 상태로 디스크에서 대기하고 있다.
    - 그러던 중 프로그램 실행 중에 이 루틴이 필요시, CPU 호출에 의해 링크, 적재된다.

- 동적 적재의 장점은 **루틴이 필요한 경우에만 적재**된다.
    - 오류 처리 루틴과 같이 아주 간혹 발생하면서도 실행할 코드가 많은 경우에 특히 유용하다.

- 동적 적재는 운영체제로부터 특별한 자원이 필요없다.
    - 사용자 자신이 프로그램의 설계를 책임져야 한다.
    - 단, 운영체제는 이를 구현하는 라이브러리 루틴을 제공할 순 있다.

### 9.1.5 동적 연결 및 공유 라이브러리

- **동적 연결 라이브러리(DLL)**는 사용자 프로그램이 실행될 때, 사용자 프로그램에 연결되는 시스템 라이브러리이다.
    - 정적 연결만 지원하는 시스템은 라이브러리가 이 프로그램의 이진 프로그램 이미지에 끼어 들어가게 된다.
    - 반대로 동적 연결은 연결(linking)이 실행 시기까지 미루어지게 된다. 이는 주로 표준 C 언어 라잉브러리와 같은 시스템 라이브러이에 사용된다.
    - 이러한 기능이 없다면 시스템의 각 프로그램은 실행 가능 이미지에 해당 언어 라이브러리의 사본을 포함해야한다.

- DDL의 장점은 **라이브러를 여러 프로세스 간에 공유할 수 있어 메인 메모리에 DLL 인스턴스가 하나만 있을 수 있다는 것**이다.
    - 따라서 DDL은 **공유 라이브러리**라고도 불린다.

- 동적 연결 라이브러리는 라이브러리 갱신으로 확장할 수 있다.
    - 또한 항상 새로운 버전으로 교체될 수 있고, 그 라이브러리를 사용하는 모든 프로그램은 자동으로 새로운 라이브러리 버전을 사용하게 된다.

- DDL은 일반적으로 운영체제의 도움을 받는다.
    - 메모리에 있는 프로세스들이 각자의 공간은 자기만 액세스할 수 있도록 보호하게 된다면,
    운영체제만이 기억 공간에 루틴이 있는지를 검사해 줄 수 있고, 여러 프로세스가 같은 메모리 주소를 공용할 수 있도록 해줄 수 있다.

## 9.2 연속 메모리 할당

- 메모리는 2가지로 나뉜다.
    1. **운영체제를 위한 것**
    2. **사용자 프로세스를 위한 것**

- 운영체제를 낮은 메모리 주소 or 높은 메모리 주소에 배치할 수 있다.
    - 이러한 결정은 인터럽트 벡터의 위치와 같은 많은 요소에 따라 달라진다.
    - 그러나 많은 운영체제가 높은 메모리에 배치되므로 그 경우만 논의하자.

- 일반적으로 여러 사용자 프로세스가 동시에 메모리에 상주하길 원한다.
    - 따라서 메모리에 적재되기를 기다리는 프로세스에 사용 가능한 메모리를 할당하는 방법을 고려해야 한다.

### 9.2.1 메모리 보호

- 프로세스가 자신이 소유하지 않은 메모리를 강제로 접근할 수 없게 할 수 있다.

![image](https://user-images.githubusercontent.com/87460638/235685689-2c5c478f-2456-4460-8ae6-7aa09551d1ac.png)

- 만약 상한 레지스터와 재배치 레지스터를 가지고 있다면 위에서 말한 것처럼 갖에로 접근을 막을 수 있다.
    - 재배치 레지스터는 최소 물리 주소값 저장, 상한 레지스터는 논리 주소의 범위 값을 저장한다.
    - MMU는 동적으로 **논리 주소 + 재배치 레지스터** 값을 주소로 변환한다.
    - 변환된 주소는 메모리로 보내진다.

### 9.2.2 메모리 할당

> 메모리를 할당하는 가장 간단한 방법은 프로세스를 **메모리의 가변 크기 파티션에 할당하는 것**이다.
> 
- 각 파티션에는 정확히 하나의 프로세스만 적재될 수 있다.
- **가변 파티션 기법**에서 운영체제는 사용 가능한 메모리 부분과 사용 중인 부분을 나타내는 테이블을 유지한다.
- 처음에는 모든 메모리가 사용자 프로세스에 사용 가능하며, 하나의 큰 사용 가능한 메모리 블록인 **hole**로 간주한다.

![image](https://user-images.githubusercontent.com/87460638/235685746-3d4501de-3135-48b3-9067-f5723f5f2a38.png)

- 처음에는 프로세스 5, 8, 2가 적재되어 있는 메모리 완전 활용 중인 상태에서 프로세스의 종료에 의해 hole이 생긴다.

⇒ *따라서 프로세스가 시스템에 들어오면, 운영체제는 각 프로세스가 메모리를 얼마나 요구하며, 사용 가능한 메모리 공간이 어디에 얼마나 있는지를 고려하여 공간을 할당해야 한다. 그 이후에 프로세스는 CPU를 할당받기 위해 경쟁한다.* 

- 이러한 기법은 **동적 메모리 할당 문제**의 특별한 예이다.
    - 이것은 일련의 가용 공간-리스트로부터 크기 n바이트 블록을 요구하는 것을 어떻게 만족시켜 줄 것이냐를 결정하는 문제이다.
- 가장 일반적인 해결 기법으로는 **최초 적합, 최적 적합, 최악 적합**이 있다.
    - **최초 적합**
    첫 번째 사용 가능한 가용 공간을 할당한다. 충분히 큰 가용 공간을 찾았을 때 검색을 끝낼 수 있다.
    - **최적 적합**
    사용 가능한 공간 중에서 가장 작은 것을 택한다. 이 방법은 아주 작은 가용 공간을 만들어 낸다.
    - **최악 적합**
    가장 큰 가용 공간을 택한다. 이 방식에서 할당해 주고 남은 가용 공간으 충분히 크기 때문에 다른 프로세스들에게 유용하게 사용될 수 있다.

### 9.2.3 단편화

- 위에서 말한 최초 적합 과 최적 적합 전략은 **외부 단편화**로 인해 어려움을 겪는다.
    - 프로세스들이 메모리에 적재되고 제거되는 일이 반복되다 보면, 어떤 가용 공간은 너무 작은 조각이 된다.
- **외부 단편화**는 이처럼 작은 조각들이 여러 곳으로 분산되어 있을 때 발생한다.
    - 즉, **메모리는 너무 많은 수의 매우 작은 조각들로 단편화되어 있는 것**이다.

- 적합 or 최적 적합 전략의 사용 유무 결정은 단편화의 크기에 영향을 받는다.
    - 또한 어느쪽 가용 공간을 할당할 것인가에 대한 고민도 영향을 받는다.

- 메모리의 전체 크기와 프로세스 크기들은 모두 외부 단편화에 따라 큰 영향을 미칠 수 있다.
    - 최초 적합의 경우 N개의 블록이 할당되었을 때 0.5N개의 블록이 단편화 때문에 손실될 수 있다. ⇒ 이 현상을 **50% 규칙**이라 한다.
    
- 메모리 공간을 낭비하는 현상인 단편화는 내부적으로도 발생할 수 있다.
    - 할당된 공간이 요구된 공간보다 약간 더 커서 두 크기 사이의 남는 부분을 **내부 단편화**라고 한다.

> 외부 단편화 문제를 해결하는 방법
> 
1.  **압축**
- 이 방법은 메모리 모든 내용을 한 군데로 몰고 모든 가용 공간을 다른 한 군데로 몰아서 큰 블록을 만드는 것이다.
    - 단, 압축은 프로세스들이 재배치가 실행 시간에 동적으로 이루어지는 경우에만 가능하다.

1. **페이징**
- 한 프로세스의 논리 주소 공간을 여러 개의 비연속적인 공간으로 나누어 필요한 크기의 공간이 가용해지는 경우 물리 메모리를 프로세스에 할당하는 방법이다.

## 9.3 페이징

- 페이징은 연속 메모리 할당의 문제였던 외부 단편화와 관련 압축의 필요성을 피한 방법이다.
- 많은 이점을 제공하기 때문에 대형 서버용 시스템부터 모바일 장치 시스템까지 다양한 형태로 페이징이 사용된다.
- 페이징은 운영체제와 컴퓨터 하드웨어 간의 협력을 통해 구현된다.

### 9.3.1 기본 방법

- 물리 메모리는 **프레임(frame)**이라 불리는 같은 크기 블록으로 나누어진다.
- 논리 메모리는 **페이지(page)**라 불리는 같은 크기의 블록으로 나누어진다.

- CPU에서 나오는 모든 주소는 **페이지 번호(p)**와 **페이지 오프셋(d: offset)** 두 개의 부분으로 나누어진다.
    
    ![image](https://user-images.githubusercontent.com/87460638/235685827-89be7071-bddd-4443-a4fe-2fd1985c82b8.png)
    
- 페이지 번호는 프로세스 **페이지 테이블(page table)**을 액세스할 때 사용된다.
- 페이지 테이블은 ***물리 메모리의 각 프레임의 시작 주소를 저장하고, 오프셋은 참조되는 프레임 안에서의 위치이다.***

⇒ 따라서 ***프레임의 시작 주소와 페이지 오프셋이 결합하여 물리 메모리 주소가 된다.***

![image](https://user-images.githubusercontent.com/87460638/235685866-f332d857-1701-41c5-8466-ac7afaf42e9e.png)

> CPU에 의해 생성된 논리 주소를 물리 주소로 변환하기 위해 MMU가 취한 단계 설명
> 
> 1. 페이지 번호 p를 추출하여 페이지 테이블의 인덱스로 사용한다.
> 2. 페이지 테이블에서 해당 프레임 번호 f를 추출한다.
> 3. 논리 주소의 페이지 번호 p를 프레임 번호 f로 바꾼다.

,,, 오프셋 d는 변하지 않기 때문에 대체되지 않으며, 프레임 번호와 오프셋은 이제 물리 주소를 구성한다.

![image](https://user-images.githubusercontent.com/87460638/235685930-12c96357-6bc3-4688-8fb2-11bcd6332c76.png)

> 논리 메모리와 물리 메모리의 페이징 모델 설명
> 
> 1. 논리 주소의 페이지 번호 p는 페이지 테이블 각 인덱스에 맞게 들어간다.
> 2. 페이지 테이블에 있는 페이지 번호 p는 물리 주소의 프레임 번호에 따라 로딩된다.

![image](https://user-images.githubusercontent.com/87460638/235685965-8fbc7a2d-6d9d-4bfc-ab31-9fdbaf142a9f.png)

> 논리주소에서 n=$2^1$, m=$2^2$ 일 때,
> 
> 1. 논리주소 0은 페이지와 오프세 모두 0이다.
> 2. 페이지 테이블을 색인으로 찾아서 페이지 0이 프레임 5에 있다는 것을 알아낸다.
>     1. 따라서 논리 주소 0의 실제 주소는 20 (= 5*4 + 0) 이다.
>     2. 나머지도 마찬가지다.

![image](https://user-images.githubusercontent.com/87460638/235686031-4b1968b8-0af0-4079-8780-3d2f0e75d3a3.png)

> 한 프로세스가 실행되기 위해 도착하면 그 프로세스의 크기가 페이지 몇 개 분에 해당하는가를 조사한다.
> 
> 1. 각 사용자 페이지는 한 프레임씩 필요하다.
>     1. 즉, 프로세스가 n개 페이지를 요구하면 메모리에서 이요할 수 있는 프레임이 n개 있어야 한다.
> 2. n개의 프레임을 사용할 수 있다면 이 프레임들은 이 프로세스에 할당한다.
> 3. 프로세스의 처음 페이지가 할당된 프레임 중 하나에 적재되고, 그 프레임 번호가 페이지 테이블에 기록된다.
> 4. 이 과정이 반복된다.

- 페이징의 가장 중요한 특징은 메모리에 대한 프로그래머의 인식과 실제 내용이 서로 다르다는 것이다.
    - 프로그래머는 메모리 하나의 연속적인 공간이며, 메모리에는 이 프로그램만 있다고 생각한다.
    - 그러나 실제는 프로그램은 여러 곳에 프레임 단위로 분산되어 있고, 많은 다른 프로그램이 올라와 있다.
- **프로그래머가 생각하는 메모리와 실제 물리 메모리의 차이는 주소 변환 하드웨어에 의해 해소된다.**

⇒ 따라서 사용자 프로세스는 자기의 것이 메모리는 접근조차 할 수 없다.

⇒ 페이지 테이블을 통하지 않고서는 다른 공간에 접근할 길이 없으며, 페이지 테이블은 그 프로세스가 소유하고 있는 페이지들만 가리키고 있기 때문이다.

- 운영체제는 물리 메모리를 관리하기 때문에 물리 메모리의 자세한 할당에 대해 파악하고 있어야 한다.
    - 즉, 어느 프레임이 할당되어 있고, 어느 프레임이 사용 가능한지, 총 프레임은 몇 개나 되는지 등을 알아야 한다.
    - 이러한 정보는 일반적으로 **프레임 테이블**이라는 시스템에 있다.

- 운영체제는 모든 프로세스의 주소들을 실제 주소로 사상할 수 있어야 한다.
    - 운영체제는 각 프로세스의 페이지 테이블 사본을 유지하는데, 논리 주소에 대응하는 물리 주소를 직접 사상해야 할 때마다 즉, 논리 주소를 물리 주소로 변환하는 데 사용된다.
    - 또한 프로세스가 CPU에 할당될 때 CPU 디스패처가 하드웨어 디스패처 테이블을 설정하는 데 사용된다.

⇒ 따라서 ***페이징은 문맥 교환 시간을 늘린다.*** 

### 9.3.2 하드웨어 지원

- 페이지 테이블의 하드웨어 구현의 가장 간단한 경우는 페이지 테이블을 전용 고속 하드웨어 레지스터 세트로 구현하는 것이다.
    - 이는 페이지 주소 변환이 매우 효율적이다.
    - 그러나 문맥 교환 시간을 증가시킨다는 단점이 있다.

- 페이지 테이블에 레지스터를 사용하는 것은 페이지 테이블이 작은 경우에 적합하다.
    - 그러나 대부분의 현대 CPU는 훨신 큰 페이지 테이블을 지원한다. ⇒ 부적절하다 !!
    
    ⇒ 따라서 대부분의 컴퓨터는 페이지 테이블을 메인 메모리에 저장하고 **페이지 테이블 기준 레지스터 (PTBR)** 로 페이지 테이블을 가리키도록 한다.
    

**9.3.2.1 Translation Look-Aside Buffer (TLB)**

- 메인 메모리에 페이지 테이블을 저장하면 문맥 교환 속도가 빨라지지만 메모리 액세스 시간이 느려질 수 있다.
    
    ⇒ 이 문제에 대한 해결로 **TLB** 라는 특수한 소형 하드웨어 캐시가 사용된다.
    
- TLB는 **매우 빠른 연관 메모리로 구성**된다.
    - TLB 내의 각 항목은 key와 value로 구성된다.

![image](https://user-images.githubusercontent.com/87460638/235686103-043ab0c8-9213-4ade-b61e-65e336c66f91.png)

> TLB 동작
> 
> 1. TLB에 페이지를 찾아달라고 요청이 들어오면 찾고자 하는 페이지를 동시에 여러 개의 내부 키(페이지 번호)와 비교한다.
> 2. 페이지 번호가 같은 것이 발견되면 그에 대응하는 페이지 번호를 알려준다.

- TLB 장단점
장점: **검색속도가 빠르고** 명령어 파이프라인의 일부로 동작하며, **성능에 손해를 끼치지 않는다.**
단점: 파이프라인 단계 동안 검색을 하기 위해서는 **TLB의 크기를 작게 유지**해야 한다.

- TLB는 **페이지 테이블의 일부만 저장한다.**
- 만약 페이지 번호가 없다면 (**TLB 미스**) 주소 변환은 앞서 얘기한 단계에 따라 진행되며, 여기서 페이지 테이블에 대한 메모리 참조가 이루어져야 한다.
    - 페이지 번호가 있어야 메모리에 액세스할 수 있다.
    
- 반대로 **TLB가 가득 차면, 기존 항목 중에서 교체될 항목을 선택해야 한다.**
    - 교체 정책은 LRU부터 라운드 로빈, 무작위 등이 사용된다.
    - 몇몇 TLB는 특정 항목들을 TLB에 고정하는데, 이러한 항목들은 TLB에서 제거될 수 없다.
        - 보통 중요 커널 코드를 TLB에 고정한다.
        
- 어떤 TLB는 각 항목에 **ASIDs (address-space indentifiers**) 를 저장하기도 한다.

- 접근하려는 메모리의 페이지 번호가 TLB에서 발견되는 비율을 **적중률(hit ratio)** 라고 한다.

- TLB는 하드웨어 구성요소이고, 따라서 운영체제와 그 설계자들에게는 영향을 주지 않는 것처럼 보인다.
    - 그러나 설계자들은 TLB의 기능과 구성요소를 이해해야 하며,
    - 이러한 것들은 하드웨어 플랫폼에 따라 달라진다.

### 9.3.3 보호

- 페이징 환경에서 메모리 보호는 각 페이지에 붙어있는 보호 비트(protection bits)에 의해 구현된다.
    - 이 비트들은 보통 페이지 테이블에 속해 있다.

- 페이지 테이블의 각 엔트리에는 **유효/무효**라는 하나의 비트가 있다.
    - **유효로 설정**되면 → 관련된 페이지가 프로세스의 **합법적인 페이지**임
    - **무효로 설정**되면 → 그 페이지는 프로세스의 **논리 주소 공간에 속하지 않음**

![image](https://user-images.githubusercontent.com/87460638/235686166-c3b2ba4c-4f50-414f-93b9-f6404a1c7353.png)

- 프로세스가 자신의 모든 주소 범위를 늘 사용하는 경우는 드물다.
    - 이런 경우에 모든 페이지 테이블 항목을 배정하는 것은 낭비다 !
    - ⇒ 따라서 몇몇 시스템은 페이지 테이블의 크기를 나타내기 위해 **페이지 테이블 길이 레지스터(PTLR)**라는 레지스터를 제공한다.
    

### 9.3.4 공유 페이지

- 페이징의 장점은 **공통의 코드를 공유할 수 있다는 점**이다.
    - 일반적인 Linux 시스템에서 대부분의 사용자 프로세스는 표준 C 라이브러리 libc가 필요하다.
    - 한 가지 옵션은 각 프로세스가 자체 libc 사본을 해당 주소 공간에 적재하도록 하는 것이다.

- 코드가 **재진입 코드**인 경우, 다음과 같이 공유할 수 있다.

![image](https://user-images.githubusercontent.com/87460638/235686226-8e63c041-aad6-43f3-b841-ffbbc8773b68.png)

> 동작 설명
> 
> 1. 라이브러리 libc에 대한 페이지를 공유하는 세 가지 프로세스가 있다.
> 2. 재진입 코드는 자체 수정을 할 수 없는 코드로서 **실행 중에는 절대 변경되지 않는다.**
> 3. 따라서 두 개 이상의 프로세스가 동일한 코드를 동시에 실행할 수 있다.
> 4. 각 프로세스에는자신의 실행을 위해 데이터를 보유하기 위한 자체 레지스터 사보노가 데이터 저장영역이 있다.
> 5. 물리 메모리에 하나의 사본만 저장하면 되고, 각 사용자 프로세스의 페이지 테이블은 동일한 물리적 사본으로 매핑시킨다.

## 9.4 페이지 테이블의 구조

### 9.4.1 계층적 페이징

- 현대 컴퓨터는 매우 큰 주소 공간을 가진다.
    - 이러한 환경에서는 페이지 테이블도 상당히 커진다.
- 예를 들어, 32비트 논리 주소 공간을 가진 시스템을 생각하면,
    - 페이지 크기가 4KB라고 할 때 → 페이지 테이블은 100만 개 이상의 항목으로 구성되며, 각 항목은 4B로 구성되므로
    - 각 프로세스는 페이지 테이블만을 위해서도 4MB의 공간이 필요하다.
    
    ⇒ 따라서 **페이지 테이블을 여러 개의 작은 조각으로 나누어 보자 !**
    

- **2단계 페이징 기법(two-level paging scheme)** 은 페이지 테이블 자체가 다시 페이징되게 하는 것이다.
    - 간단히 요약하면, **페이지 테이블의 페이지화**를 의미한다.

![image](https://user-images.githubusercontent.com/87460638/235686295-0917f769-8bd7-4517-9a86-da8043108b10.png)

![image](https://user-images.githubusercontent.com/87460638/235686341-6c9c8053-0406-439f-96d0-9af515d7026d.png)

> 앞서 예로 들었던 4KB 크기를 가진 32비트 기계를 다시 들어보자.
> 
> - 이 경우 논리주소는 20비트 페이지 번호와 12비트 페이지 오프셋으로 이루어진다.
> - 페이지 테이블도 페이지로 나누어지기 때문에 페이지 번호는 다시 10비트 페이지 번호와 페10비트 페이지 오프셋으로 나눠진다.
>     - 여기서 p1 = 바깥 페이지 테이블의 인덱스이고, p2 = 안쪽 페이지 테이블의 오프셋 이다.

⇒ 이 방식에서는 주소 변환이 바깥 페이지 테이블에서 안쪽으로 들어오므로 

- 이 방식을 **forward-mapped 페이지 테이블**이라고도 부른다.

### 9.4.2 해시 페이지 테이블

- 주소 공간이 32비트보다 커지면 가상 주소를 해시로 사용하는 **해시 페이지 테이블**을 많이 쓴다.
- 해시 페이지 테이블의 각 항목은 연결 리스트를 가지고 있다.
    - 이곳에는 충돌을 일으켜서 모두 이곳으로 해시되는 원소들이 매달리게 된다.
    - 각 원소는 3개의 필드를 가진다:
        
        **(1) 가상 페이지 번호 (2) 사상되는 페이지 프레임 번호 (3) 연결 리스트상의 다음 원소 포인터**
        

![image](https://user-images.githubusercontent.com/87460638/235686426-9356d8e8-b6cb-4445-a355-8656974696aa.png)

> 이 알고리즘은 다음과 같이 작동된다.
> 
> - 가장 주소 공간으로부터 페이지 번호가 오면 → 그것을 해싱한다.
> - 그것으로 해시 페이지 테이블에서 연결 리스트를 따라가며 첫 번재 원소와 가상 페이지 번호를 비교해 본다.
> - 일치되면 → 그에 대응하는 페이지 프레임 번호를 가져와 물리 주소를 얻고
> 불일치하면 → 연결 리스트의 그 다음 원소로 똑같은 일을 반복한다.

- 64비트 시스템에서 유용하도록 변형된 해시 테이블 기법이 제안되었다.
    - 이 기법은 해시 테이블과 비슷한 **클러스터 페이지 테이블**을 사용한다.

### 9.4.3 역 페이지 테이블

- 보통 프로세스 하나당 페이지 테이블은 하나의 항목을 가진다.
    - 메모리가 어떻게 사용되고 있는가에 대한 정보를 유지하기 위해 많은 양의 물리적 메모리 공간을 소비한다.

⇒ 이 문제를 해결하기 위한 방법이 **역 페이지 테이블(inverted page table)**이다.

- 역 페이지 테이블은 메모리 프레임마다 한 항목씩을 할당한다.
    - 각 항목은 그 프레임에 올라와 있는 페이지 주소, 그 페이지를 소유하고 있는 프로세스의 ID를 표시한다.
    - 이렇게 되면 시스템에는 단 하나의 페이지 테이블만이 존재하게 되고, 테이블 내 각 항목은 메모리 한 프레임씩을 가리키게 된다.

![image](https://user-images.githubusercontent.com/87460638/235686489-5f2ac5da-e024-4aff-baa5-0525d5628891.png)

- 역 페이지들은 종종 각각의 페이지 테이블 엔트리에 저장되는 주소 공간 ID를 요구한다.
    - 왜? 테이블은 보통 물리공간을 사상하는 서로 다른 주소 공간이 혼재하고 있기 때문 !
- 주소 공간 ID를 저장함으로써 특정 프로세스의 논리 페이지가 그에 상응하는 물리 페이지 프레임과 사상되었다는 것을 보장한다.

- 이 방법은 논리 페이지마다 항목을 가지는 대신, 물리 프레임에 대응되는 항목만 테이블에 저장하기 때문에 ⇒ 메모리에서 훨씬 작은 공간을 점유한다.
    - 그러나 주소변환 시간이 더 오래 걸릴 수 있다.
    
    ⇒ 이를 해결하기 위해 앞서 얘기했던 해시 테이블을 사용한다.
    

### 9.4.4 Oracle SPARC Solaris

- SPARC PC에서 실행되는 Solaris는 완전한 64비트 운영체제이다.
    - 여러 단계의 페이지 테이블을 메모리에 유지하기 위해 물리 메모리를 소진하지 않으면서 가상 메모리 문제를 해결해야만 한다.
    - ⇒ 이 문제는 해시 테이블을 사용하여 해결할 수 있다.

## 9.5 스와핑

- 프로세스가 실행되기 위해서는 프로세스의 명령어와 명령어가 접근하는 데이터가 메모리에 있어야 한다.
    - 그러나 프로세스 또는 프로세스의 일부부분은 실행 중에 임시로 **백업 저장장치**로 내보내졌다가 실행을 위해 다시 메모리로 돌아올 수 있다.
    - ⇒ 이는 다중 프로그래밍의 정도를 증가시킨다.

### 9.5.1 기본 스와핑

- 표준 스와핑은 메인 메모리와 백업 저장장치 간에 전체 프로세스를 이동한다.
- 백업 저장장치는 일반적으로 빠른 보조저장장치이다.
    - 저장 및 다시 접근해야 하는 프로세스의 크기에 상관없이 수용할 수 있을 만큼 커야 하며,
    - 이러한 메모리 이미지에 직접 액세스할 수 있어야 한다.

![image](https://user-images.githubusercontent.com/87460638/235686553-b31c9deb-bdf4-46c3-8ac4-a4307505382d.png)

- 디중 스레드 프로세스의 경우,
    - 모든 스레드 당 데이터 구조도 스왑되어야 한다.
    - 또한, 운영체제는 스왑아웃된 프로세스에 대한 메타데이터를 유지해야 메모리로 다시 스왑인될 때 복원될 수 있다.

- 표준 스와핑의 장점은
    - 실제 물리 메모리보다 더 많은 프로세스를 수용할 수 있도록 **물리 메모리가 초과 할당될 수 있다는 것**이다.

### 9.5.2 페이징에서의 스와핑

- 표준 스와핑은 메모리와 백업 저장장치 간에 프로세스 전체를 이동하는 데 걸리는 시간이 엄청나기 때문에 일반적으로 최신 운영체제에서는 더는 사용되지 않는다.
- Linux 및 Windows를 포함한 대부분의 시스템은 프로세스 전체가 아닌 프로세스 페이지를 스왑할 수 있는 변형 스와핑을 사용한다.
    - 이 전략은 여전히 물리 메모리를 초과 할당할 수 있지만,
    - 프로세스 전체를 스왑하는 비용은 발생하지 않는다.

![image](https://user-images.githubusercontent.com/87460638/235686605-690d3c67-0840-4c6f-9038-595dfc04a188.png)

- **페이징 아웃 연산** : 페이지를 메모리에서 백업 저장장치로 이동시킨다.
- **페이지 인 연산** : 페이징 아웃 연산의 반대방향의 연산을 말한다. (백업 저장장치 → 메모리)

### 9.5.3 모바일 시스템에서의 스와핑

- 모바일 시스템은 어떠한 형태의 스와핑도 지원하지 않는 것이 일반적이다.
    - iOS 는 자유 메모리가 정해진 임계값보다 떨어지면, 응용에 할당된 메모리를 자발적으로 반환하도록 요청한다.
    - Android는 iOS와 유사한 정책을 채택하며, 자유 메모리가 부족하면 프로세스를 종료시키는 것이 가능하다.

⇒ 이러한 제약 사항들 때문에 모바일 운영체제 개발자들은 응용이 너무 많은 메모리를 사용하거나 or 메모리 누수로 고생하지 않도록 주의해서 메모리를 할당하고 반환해야 한다.

## 9.6 사례: Intel 32비트와 64비트 구조

### 9.6.1 IA-32 구조

![image](https://user-images.githubusercontent.com/87460638/235686650-eccac8d4-5588-49f3-87ad-1b2eb7ba45c2.png)

- **IA-32 시스템**의 메모리 관리는 세그먼테이션과 페이징의 두 부분으로 나눌 수 있다.
    - CPU는 논리 주소를 생성하고, 이 주소는 세그먼테이션 장치에 전달된다.
    - 세그먼테이션 장치는 논리 주소에 상응하는 선형 주소를 생성한다.
    - 선형 주소는 페이징 장치에 전달되고, 메인 메모리의 물리 주소로 변환된다.

### 9.6.2 x86-64

![image](https://user-images.githubusercontent.com/87460638/235686697-392edb50-1c79-4470-b214-824e5c394840.png)

- **x86-64**는 훨신 큰 논리 및 물리 주소 공간을 지원하고 구조적으로 많은 개선을 하였다.
    - 4KB, 2MB, 1GB 페이지를 지원할 수 있는 4단계 페이지 테이블을 사용하는 48-비트 가상 주소 공간을 지원한다.

## 9.7 사례: ARM 구조

![image](https://user-images.githubusercontent.com/87460638/235686740-5bf540d2-5f8f-41f2-a364-e2c20794e1eb.png)

- ARMv8에는 4KB, 16KB, 64KB 의 세 가지 변환 단위가 있다.
    - 각 변환 단위는 다른 페이지 크기뿐만 아니라 **region**이라는 더 큰 연속적인 메모리 영역도 제공한다.
    
- ARM 아키텍처는 두 가지 수준(2-level) TLB 도 지원한다.
    - 내부 레벨에는 2개의 **마이크로 TLB**가 각각 명령어와 데이터를 위해 존재한다.
    - 외부 레벨에는 1개의 **메인 TLB**가 있다.
